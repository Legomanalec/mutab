{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "\n",
    "with open('../data/full_tab_string.txt') as small_pf:\n",
    "\n",
    "    tmp_list = []\n",
    "    for line in small_pf:\n",
    "        line = line.rstrip(\"\\n\")\n",
    "        if line == \"\":\n",
    "            lst.append(tmp_list)\n",
    "            tmp_list = []\n",
    "        else:\n",
    "            tmp_list.extend(line.split())\n",
    "\n",
    "    if tmp_list:  # add last one\n",
    "        lst.append(tmp_list)\n",
    "lst = lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "with open('../data/full_tab_string.txt') as small_pf:\n",
    "    text = small_pf.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can't use set because tab encodings are not hashable types\n",
    "def unique(list1):\n",
    "    unique_set = set()\n",
    "    for x in list1:\n",
    "        if x not in unique_set:\n",
    "            unique_set.add(x)\n",
    "    return unique_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all tab locations\n",
    "tab_vocab = unique(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', 'G22', 'e5', 'G24', 'A9', 'E14', 'E3', 'B14', 'E55', 'A6', 'G99', 'D77', 'D9', 'A7', 'G10', 'e18', 'A15', 'D19', 'G81', 'D0', 'G91', 'D17', 'G2', 'B20', 'E22', 'E33', 'E7', 'e0', 'G5', 'E77', 'E13', 'e17', 'e77', 'e20', 'D13', 'B9', 'D7', 'G18', 'G19', 'G0', 'B88', 'B18', 'G12', 'G17', 'D4', 'e24', 'B31', 'e4', 'G9', 'e1', 'D3', 'B5', 'E11', 'D22', 'B8', 'e10', 'D14', 'E19', 'G42', 'B6', 'e15', 'B10', 'e6', 'B3', 'A54', 'D2', 'D1', 'A11', 'G4', 'A57', 'e9', 'B19', 'B4', 'G16', 'G15', 'E16', 'e11', 'e71', 'A22', 'E12', 'e28', 'D75', 'A33', 'E1', 'B21', 'G21', 'G61', 'A2', 'e14', 'B13', 'E57', 'E4', 'e8', 'G1', 'e7', 'D10', 'B11', 'B51', 'A19', 'A16', 'G14', 'B16', 'A17', 'B12', 'e21', 'B22', 'e51', 'G3', 'E17', 'e16', 'A12', 'E9', 'A77', 'A25', 'G8', 'E0', 'G92', 'A8', 'G6', 'G7', 'e22', 'B0', 'G40', 'D6', 'B2', 'A4', 'e3', 'D11', 'B33', 'A3', 'D12', 'B24', 'A14', 'A75', 'D8', 'D25', 'A45', 'e23', 'B17', 'G13', 'B71', 'D5', 'E6', 'A44', 'B53', 'E10', 'A0', 'E5', 'D15', 'G11', 'G23', 'E2', 'e2', 'B7', 'e13', 'B23', 'E8', 'A52', 'D16', 'A5', 'E34', 'A13', 'A99', 'e19', 'G20', 'B1', 'D52', 'D20', 'A1', 'E15', 'B15', 'e12', 'A10']\n"
     ]
    }
   ],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    num_oov_indices = 1, \n",
    "    vocabulary=list(tab_vocab), \n",
    "    mask_token=None)\n",
    "print(ids_from_chars.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids) + \" \", axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = ids_from_chars(tf.strings.split(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.from_tensor_slices_op.TensorSliceDataset"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "type(ids_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D7\n",
      "G5\n",
      "B5\n",
      "e5\n",
      "e7\n",
      "D6\n",
      "B5\n",
      "G5\n",
      "e7\n",
      "e8\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "tf.Tensor(\n",
      "[b'D7' b'G5' b'B5' b'e5' b'e7' b'D6' b'B5' b'G5' b'e7' b'e8' b'D5' b'B5'\n",
      " b'G5' b'e8' b'e2' b'D4' b'B3' b'G2' b'e2' b'e0' b'D3'], shape=(21,), dtype=string)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "print(type(sequences))\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))\n",
    "  print(type(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'D7 G5 B5 e5 e7 D6 B5 G5 e7 e8 D5 B5 G5 e8 e2 D4 B3 G2 e2 e0 D3 '\n",
      "b'B1 G2 B1 e0 B1 G2 B0 G0 A2 B1 G2 A0 B1 G2 A0 G2 A0 A8 A7 A0 D7 '\n",
      "b'G5 B5 e7 D6 B5 G5 e7 e8 D5 B5 G5 e8 e2 D4 B3 G2 e2 e0 D3 B1 G2 '\n",
      "b'B1 e0 B1 G2 B0 G0 A2 B1 G2 A0 B1 G2 A0 A0 A2 A3 D2 G0 e0 e2 D0 '\n",
      "b'B3 G2 e2 e0 D3 B1 G2 e0 B0 A0 B1 G2 A0 A2 B1 A3 G0 D2 B1 e3 E3 '\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BatchDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4416\\3160607509.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msplit_input_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4416\\557121777.py\u001b[0m in \u001b[0;36msplit_input_target\u001b[1;34m(sequence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msplit_input_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0minput_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtarget_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minput_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'BatchDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "split_input_target(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=(TensorSpec(shape=(20,), dtype=tf.int64, name=None), TensorSpec(shape=(20,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = sequences.map(split_input_target)\n",
    "dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'D7 G5 B5 e5 e7 D6 B5 G5 e7 e8 D5 B5 G5 e8 e2 D4 B3 G2 e2 e0 '\n",
      "Target: b'G5 B5 e5 e7 D6 B5 G5 e7 e8 D5 B5 G5 e8 e2 D4 B3 G2 e2 e0 D3 '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 20), dtype=tf.int64, name=None), TensorSpec(shape=(64, 20), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "\n",
    "    #adjust the dense units size                         \n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 20, 173) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  44288     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  177325    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,159,917\n",
      "Trainable params: 4,159,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14, 122, 132,  93,  85, 116,  54, 135, 143,  78, 143,  75, 139,\n",
       "        52, 134,  58,  89,  68, 100, 118], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'D7 e2 B3 G4 A2 D7 e2 B3 G4 A2 D7 e3 B5 G5 A3 D4 e3 B5 G5 A3 '\n",
      "\n",
      "Next Char Predictions:\n",
      " b'G10 G40 A14 G1 G21 G92 B8 D25 A44 A22 A44 E16 G13 E11 D8 G42 B13 G4 G14 G6 '\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 20, 173)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(5.154606, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './tab_training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "130/130 [==============================] - 31s 225ms/step - loss: 3.3786\n",
      "Epoch 2/4\n",
      "130/130 [==============================] - 29s 223ms/step - loss: 2.4908\n",
      "Epoch 3/4\n",
      "130/130 [==============================] - 29s 224ms/step - loss: 2.1554\n",
      "Epoch 4/4\n",
      "130/130 [==============================] - 30s 232ms/step - loss: 1.8408\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "\n",
    "    #USE THIS TO CHANGE WHICH OUTPUTS ARE ALLOWED\n",
    "    skip_ids = self.ids_from_chars(['[UNK]', 'G22', 'e5', 'G24', \n",
    "    'A9', 'E14', 'E3', 'B14', 'E55', 'A6', 'G99', 'D77', 'D9', \n",
    "    'A7', 'G10', 'e18', 'A15', 'D19', 'G81', 'D0', 'G91', 'D17', \n",
    "    'G2', 'B20', 'E22', 'E33', 'E7', 'e0', 'G5', 'E77', 'E13', \n",
    "    'e17', 'e77', 'e20', 'D13', 'B9', 'D7', 'G18', 'G19', 'G0', \n",
    "    'B88', 'B18', 'G12', 'G17', 'D4', 'e24', 'B31', 'e4', 'G9', \n",
    "    'e1', 'D3', 'B5', 'E11', 'D22', 'B8', 'e10', 'D14', 'E19', \n",
    "    'G42', 'B6', 'e15', 'B10', 'e6', 'B3', 'A54', 'D2', 'D1', \n",
    "    'A11', 'G4', 'A57', 'e9', 'B19', 'B4', 'G16', 'G15', 'E16', \n",
    "    'e11', 'e71', 'A22', 'E12', 'e28', 'D75', 'A33', 'E1', 'B21', \n",
    "    'G21', 'G61', 'A2', 'e14', 'B13', 'E57', 'E4', 'e8', 'G1', \n",
    "    'e7', 'D10', 'B11', 'B51', 'A19', 'A16', 'G14', 'B16', 'A17', \n",
    "    'B12', 'e21', 'B22', 'e51', 'G3', 'E17', 'e16', 'A12', 'E9', \n",
    "    'A77', 'A25', 'G8', 'E0', 'G92', 'A8', 'G6', 'G7', 'e22', 'B0', \n",
    "    'G40', 'D6', 'B2', 'A4', 'e3', 'D11', 'B33', 'A3', 'D12', 'B24', \n",
    "    'A14', 'A75', 'D8', 'D25', 'A45', 'e23', 'B17', 'G13', 'B71', \n",
    "    'D5', 'E6', 'A44', 'B53', 'E10', 'A0', 'E5', 'D15', 'G23', \n",
    "    'E2', 'e13', 'B23', 'E8', 'A52', 'A5', 'E34', \n",
    "    'A13', 'A99', 'e19', 'G20', 'B1', 'D52', 'D20', 'A1', 'E15', 'B15', \n",
    "    'e12', 'A10'])[:, None]\n",
    "\n",
    "    # skip_ids = self.ids_from_chars('[UNK]', 'G3', 'B22', 'E3', 'B11', \n",
    "    # 'G5', 'e22', 'A9', 'G19', 'D2', 'G21', 'E4', 'D16', 'E14', 'D7', \n",
    "    # 'G14', 'G17', 'D6', 'B0', 'e3', 'A4', 'G81', 'D19', 'D4', 'D14', \n",
    "    # 'E2', 'G11', 'B2', 'B18', 'e18', 'E13', 'B14', 'G16', 'A0', 'E15', \n",
    "    # 'E6', 'e2', 'e7', 'E11', 'B5', 'B4', 'e15', 'A8', 'D8', 'G6', 'D13', \n",
    "    # 'G4', 'A16', 'B15', 'B7', 'B3', 'A12', 'A17', 'E8', 'e23', 'B9', \n",
    "    # 'A15', 'e4', 'E19', 'A5', 'D15', 'D5', 'B1', 'A10', 'A7', 'e8', \n",
    "    # 'e19', 'B13', 'A19', 'D11', 'D12', 'D17', 'e24', 'B6', 'A2', 'A3', \n",
    "    # 'A6', 'e13', 'e16', 'B24', 'e1', 'e10', 'G2', 'G1', 'G8', 'A11', \n",
    "    # 'G12', 'E17', 'e20', 'G13', 'B17', 'D1', 'E10', 'e12', 'B19', 'D10',\n",
    "    #  'B20', 'A13', 'e5', 'G10', 'G0', 'E0', 'B12', 'e0', 'e14', \n",
    "    #  'A14', 'G9', 'B16', 'A1', 'e9', 'D3', 'e6', 'B8', 'A33', 'G7', \n",
    "    #  'E5', 'D9', 'e11', 'e17', 'E1', 'E9', 'B21', 'B10', 'G18', 'E12', \n",
    "    #  'D0', 'e21', 'E7', 'G15')\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D9 D11 G9 B7 \n"
     ]
    }
   ],
   "source": [
    "#get more than 3 Epochs to decrease loss for better predictions. This is, i believe the perfect basis \n",
    "#for getting tab to work.\n",
    "histthis = []\n",
    "for i in range(100):\n",
    "  states = None\n",
    "  next_char = tf.constant(['D9 D11 G9'])\n",
    "  result = [next_char + \" \"]\n",
    "  for n in range(1):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char + \" \")\n",
    "\n",
    "  result = tf.strings.join(result)\n",
    "\n",
    "  if result[0].numpy().decode('utf-8') == 'D9 D11 G9 G11 ':\n",
    "    histthis.append(0)\n",
    "  elif result[0].numpy().decode('utf-8') == 'D9 D11 G9 B7 ':\n",
    "    histthis.append(1)\n",
    "  elif result[0].numpy().decode('utf-8') == 'D9 D11 G9 e2 ':\n",
    "    histthis.append(2)\n",
    "  elif result[0].numpy().decode('utf-8') == 'D9 D11 G9 d16 ':\n",
    "    histthis.append(3)\n",
    "print(result[0].numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histthis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model appears to be successfully predicting, but the fact that it predicts an e2 here consistantly is not good. Will need to clean things up and check what is going on. I could be testing things wrong. Not sure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9.,  0.,  0.,  0.,  0., 58.,  0.,  0.,  0., 22.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(histthis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b6ddfb2dcac28d85c50c41a252d540a7fa8764b66ffa4029a84ab1fab305572"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
